{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating the chrome browser\n",
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "\n",
    "#opening the homepage of amzon\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"twotabsearchtextbox\")   #locating search bar by id\n",
    "search_field_designation.send_keys(\"laptop\")                                #searching for laptops\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\")         #clicking the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Rating=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n",
      "Product urls of page 4 has been scraped.\n",
      "Product urls of page 5 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=5\n",
    "urls =[]\n",
    "for page in range(start,end):       #for loop for scrapping 3 page\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls of products on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')           # Scraping the url from webelement\n",
    "            if url[0:4]=='http':                # Checking if the scraped data is a valid url or not\n",
    "                urls.append(url)                # Appending the url to urls list\n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        nxt_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')      # Locating the next_button which is active\n",
    "        if nxt_button.text == 'Next→':                                            # Checking if the button located is next button\n",
    "            nxt_button.click()                                                    # Clicking the next button\n",
    "            time.sleep(5)                                                         # time delay of 5 seconds\n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)                               # ReLoading the ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pop = driver.find_element_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/i[2]')     # Button for expanding the specs\n",
    "        pop.click()\n",
    "        time.sleep(2)\n",
    "       \n",
    "        rev=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base a-text-center']/a\") #button for expanding review list\n",
    "        rev.click() \n",
    "        time.sleep(2)\n",
    "        \n",
    "        star5=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[1]\")  #locating the 5star ratings\n",
    "        star5.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)  #appending the review in Review list\n",
    "        \n",
    "        star4=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]\")  #locating the 4star rating\n",
    "        star4.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star3=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]\")  #locating the 3star rating\n",
    "        star3.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star2=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]\")  #locating the 2star rating\n",
    "        star2.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        time.sleep(2)\n",
    "        \n",
    "        star1=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]\")  #locating the 1star rating\n",
    "        star1.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Rating.append(\"NO rating\")   #appending the No rating if no rating is there   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 461)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Large quality display with decent performance',\n",
       " 'Good product from lenovo',\n",
       " 'Good laptop, but the screen resolution is not great',\n",
       " 'Good laptop, but the screen resolution is not great',\n",
       " 'DONT BUY !']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NO rating', 'NO rating', 'NO rating', 'NO rating', '5 star']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rating                                             Review\n",
      "0    NO rating      Large quality display with decent performance\n",
      "1    NO rating                           Good product from lenovo\n",
      "2    NO rating  Good laptop, but the screen resolution is not ...\n",
      "3    NO rating  Good laptop, but the screen resolution is not ...\n",
      "4       5 star                                         DONT BUY !\n",
      "..         ...                                                ...\n",
      "388     5 star                      Fpr doesn't function properly\n",
      "389     5 star                                      Great Product\n",
      "390     4 star                                      Great Product\n",
      "391     3 star                                      Great Product\n",
      "392  NO rating                                  Light and Compact\n",
      "\n",
      "[393 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "amaz_lap=pd.DataFrame({'Rating':Rating[:393],\n",
    "                'Review':Review[:393]})\n",
    "#printing dataframe\n",
    "print(amaz_lap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "amaz_lap.to_csv('amaz_lap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating the chrome browser\n",
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "\n",
    "#opening the homepage of amzon\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"twotabsearchtextbox\")   #locating search bar by id\n",
    "search_field_designation.send_keys(\"phones\")                                #searching for phones\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\")         #clicking the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Rating=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n",
      "Product urls of page 4 has been scraped.\n",
      "Product urls of page 5 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=5\n",
    "urls =[]\n",
    "for page in range(start,end):       #for loop for scrapping 3 page\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls of products on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')           # Scraping the url from webelement\n",
    "            if url[0:4]=='http':                # Checking if the scraped data is a valid url or not\n",
    "                urls.append(url)                # Appending the url to urls list\n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        nxt_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')      # Locating the next_button which is active\n",
    "        if nxt_button.text == 'Next→':                                            # Checking if the button located is next button\n",
    "            nxt_button.click()                                                    # Clicking the next button\n",
    "            time.sleep(5)                                                         # time delay of 5 seconds\n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)                               # ReLoading the ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pop = driver.find_element_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/i[2]')     # Button for expanding the specs\n",
    "        pop.click()\n",
    "        time.sleep(2)\n",
    "       \n",
    "        rev=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base a-text-center']/a\") #button for expanding review list\n",
    "        rev.click() \n",
    "        time.sleep(2)\n",
    "        \n",
    "        star5=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[1]\")  #locating the 5star ratings\n",
    "        star5.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)  #appending the review in Review list\n",
    "        \n",
    "        star4=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]\")  #locating the 4star rating\n",
    "        star4.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star3=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]\")  #locating the 3star rating\n",
    "        star3.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star2=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]\")  #locating the 2star rating\n",
    "        star2.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        time.sleep(2)\n",
    "        \n",
    "        star1=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]\")  #locating the 1star rating\n",
    "        star1.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Rating.append(\"NO rating\")   #appending the No rating if no rating is there   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523, 639)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rating                                             Review\n",
      "0    5 star                                 Some extra to know\n",
      "1    5 star  If your purpose is gaming then go iqoo or else...\n",
      "2    4 star                       Pleae Read before U purchase\n",
      "3    3 star                            Only hipe. Nothing New.\n",
      "4    2 star                            Only hipe. Nothing New.\n",
      "..      ...                                                ...\n",
      "518  5 star                                      Awesome phone\n",
      "519  5 star                                      Awesome phone\n",
      "520  4 star                                      Awesome phone\n",
      "521  3 star                                      Awesome phone\n",
      "522  2 star                                    Excellent Phone\n",
      "\n",
      "[523 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "amaz_phon=pd.DataFrame({'Rating':Rating[:523],\n",
    "                'Review':Review[:5233]})\n",
    "#printing dataframe\n",
    "print(amaz_phon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "amaz_phon.to_csv('amaz_phon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating the chrome browser\n",
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "\n",
    "#opening the homepage of amzon\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"twotabsearchtextbox\")   #locating search bar by id\n",
    "search_field_designation.send_keys(\"headphones\")                                #searching for headphones\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\")         #clicking the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Rating=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n",
      "Product urls of page 4 has been scraped.\n",
      "Product urls of page 5 has been scraped.\n",
      "Product urls of page 6 has been scraped.\n",
      "Product urls of page 7 has been scraped.\n",
      "Product urls of page 8 has been scraped.\n",
      "Product urls of page 9 has been scraped.\n",
      "Product urls of page 10 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=10\n",
    "urls =[]\n",
    "for page in range(start,end):       #for loop for scrapping 3 page\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls of products on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')           # Scraping the url from webelement\n",
    "            if url[0:4]=='http':                # Checking if the scraped data is a valid url or not\n",
    "                urls.append(url)                # Appending the url to urls list\n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        nxt_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')      # Locating the next_button which is active\n",
    "        if nxt_button.text == 'Next→':                                            # Checking if the button located is next button\n",
    "            nxt_button.click()                                                    # Clicking the next button\n",
    "            time.sleep(5)                                                         # time delay of 5 seconds\n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)                               # ReLoading the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pop = driver.find_element_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/i[2]')     # Button for expanding the specs\n",
    "        pop.click()\n",
    "        time.sleep(2)\n",
    "       \n",
    "        rev=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base a-text-center']/a\") #button for expanding review list\n",
    "        rev.click() \n",
    "        time.sleep(2)\n",
    "        \n",
    "        star5=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[1]\")  #locating the 5star ratings\n",
    "        star5.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)  #appending the review in Review list\n",
    "        \n",
    "        star4=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]\")  #locating the 4star rating\n",
    "        star4.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star3=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]\")  #locating the 3star rating\n",
    "        star3.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star2=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]\")  #locating the 2star rating\n",
    "        star2.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        time.sleep(2)\n",
    "        \n",
    "        star1=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]\")  #locating the 1star rating\n",
    "        star1.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Rating.append(\"NO rating\")   #appending the No rating if no rating is there   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 1918)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Rating                                             Review\n",
      "0        5 star         Exquisite Headphones! Head Turning Design!\n",
      "1        5 star          Killer Bluetooth headset within budget.!!\n",
      "2        4 star  Micro phone is worst. Sound quality is very good.\n",
      "3        3 star                                 Pretty bad product\n",
      "4        2 star  Does not deliver upto it's pricing. Causes hea...\n",
      "...         ...                                                ...\n",
      "1591     5 star          Killer Bluetooth headset within budget.!!\n",
      "1592     4 star          Killer Bluetooth headset within budget.!!\n",
      "1593     3 star                    Great Performance for the Price\n",
      "1594     2 star                                       Good product\n",
      "1595  NO rating                                       Good product\n",
      "\n",
      "[1596 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "amaz_headph=pd.DataFrame({'Rating':Rating[:1596],\n",
    "                'Review':Review[:1596]})\n",
    "#printing dataframe\n",
    "print(amaz_headph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "amaz_headph.to_csv('amaz_headph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating the chrome browser\n",
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "\n",
    "#opening the homepage of amzon\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"twotabsearchtextbox\")   #locating search bar by id\n",
    "search_field_designation.send_keys(\"smartwatches\")                                #searching for smartwatches\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\")         #clicking the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Rating=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n",
      "Product urls of page 4 has been scraped.\n",
      "Product urls of page 5 has been scraped.\n",
      "Product urls of page 6 has been scraped.\n",
      "Product urls of page 7 has been scraped.\n",
      "Product urls of page 8 has been scraped.\n",
      "Product urls of page 9 has been scraped.\n",
      "Product urls of page 10 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=10\n",
    "urls =[]\n",
    "for page in range(start,end):       #for loop for scrapping 3 page\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls of products on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')           # Scraping the url from webelement\n",
    "            if url[0:4]=='http':                # Checking if the scraped data is a valid url or not\n",
    "                urls.append(url)                # Appending the url to urls list\n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        nxt_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')      # Locating the next_button which is active\n",
    "        if nxt_button.text == 'Next→':                                            # Checking if the button located is next button\n",
    "            nxt_button.click()                                                    # Clicking the next button\n",
    "            time.sleep(5)                                                         # time delay of 5 seconds\n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)                               # ReLoading the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pop = driver.find_element_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/i[2]')     # Button for expanding the specs\n",
    "        pop.click()\n",
    "        time.sleep(2)\n",
    "       \n",
    "        rev=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base a-text-center']/a\") #button for expanding review list\n",
    "        rev.click() \n",
    "        time.sleep(2)\n",
    "        \n",
    "        star5=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[1]\")  #locating the 5star ratings\n",
    "        star5.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)  #appending the review in Review list\n",
    "        \n",
    "        star4=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]\")  #locating the 4star rating\n",
    "        star4.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star3=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]\")  #locating the 3star rating\n",
    "        star3.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star2=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]\")  #locating the 2star rating\n",
    "        star2.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        time.sleep(2)\n",
    "        \n",
    "        star1=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]\")  #locating the 1star rating\n",
    "        star1.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Rating.append(\"NO rating\")   #appending the No rating if no rating is there   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 550)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rating                                             Review\n",
      "0    NO rating   The best watch I've ever bought! #iWatch #Apple#\n",
      "1    NO rating   The best watch I've ever bought! #iWatch #Apple#\n",
      "2    NO rating   The best watch I've ever bought! #iWatch #Apple#\n",
      "3    NO rating   The best watch I've ever bought! #iWatch #Apple#\n",
      "4    NO rating                Scratch found on the Watch screen..\n",
      "..         ...                                                ...\n",
      "326     5 star               Special superb watch 2.0 is the best\n",
      "327     4 star                                             Reflex\n",
      "328     3 star                                     Facing problem\n",
      "329     2 star  Not good! Getting better features for same price.\n",
      "330     5 star                                I got a bad product\n",
      "\n",
      "[331 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "amaz_smart=pd.DataFrame({'Rating':Rating[:331],\n",
    "                'Review':Review[:331]})\n",
    "#printing dataframe\n",
    "print(amaz_smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "amaz_smart.to_csv('amaz_smart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating the chrome browser\n",
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "\n",
    "#opening the homepage of amzon\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"twotabsearchtextbox\")   #locating search bar by id\n",
    "search_field_designation.send_keys(\"camera\")                                #searching for camera\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\")         #clicking the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Rating=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n",
      "Product urls of page 4 has been scraped.\n",
      "Product urls of page 5 has been scraped.\n",
      "Product urls of page 6 has been scraped.\n",
      "Product urls of page 7 has been scraped.\n",
      "Product urls of page 8 has been scraped.\n",
      "Product urls of page 9 has been scraped.\n",
      "Product urls of page 10 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=10\n",
    "urls =[]\n",
    "for page in range(start,end):       #for loop for scrapping 3 page\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls of products on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')           # Scraping the url from webelement\n",
    "            if url[0:4]=='http':                # Checking if the scraped data is a valid url or not\n",
    "                urls.append(url)                # Appending the url to urls list\n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        nxt_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')      # Locating the next_button which is active\n",
    "        if nxt_button.text == 'Next→':                                            # Checking if the button located is next button\n",
    "            nxt_button.click()                                                    # Clicking the next button\n",
    "            time.sleep(5)                                                         # time delay of 5 seconds\n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)                               # ReLoading the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pop = driver.find_element_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/i[2]')     # Button for expanding the specs\n",
    "        pop.click()\n",
    "        time.sleep(2)\n",
    "       \n",
    "        rev=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base a-text-center']/a\") #button for expanding review list\n",
    "        rev.click() \n",
    "        time.sleep(2)\n",
    "        \n",
    "        star5=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[1]\")  #locating the 5star ratings\n",
    "        star5.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)  #appending the review in Review list\n",
    "        \n",
    "        star4=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]\")  #locating the 4star rating\n",
    "        star4.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star3=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]\")  #locating the 3star rating\n",
    "        star3.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star2=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]\")  #locating the 2star rating\n",
    "        star2.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        time.sleep(2)\n",
    "        \n",
    "        star1=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]\")  #locating the 1star rating\n",
    "        star1.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Rating.append(\"NO rating\")   #appending the No rating if no rating is there   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 2493)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Rating                                             Review\n",
      "0        5 star                 A match for more expensive cameras\n",
      "1        5 star  Perfect camera... ruined by proprietery USB cable\n",
      "2        4 star  The 3 stars are due to seller and amazon deliv...\n",
      "3        3 star                                 No value for money\n",
      "4        2 star                       32gd card and pouch not free\n",
      "...         ...                                                ...\n",
      "2016  NO rating                                   Best camera ever\n",
      "2017     5 star                      Old world charm, once again..\n",
      "2018     5 star                                         Fun camera\n",
      "2019     5 star                                Not value for money\n",
      "2020     5 star                                           Good one\n",
      "\n",
      "[2021 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "amaz_cam=pd.DataFrame({'Rating':Rating[:2021],\n",
    "                'Review':Review[:2021]})\n",
    "#printing dataframe\n",
    "print(amaz_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "amaz_cam.to_csv('amaz_cam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating the chrome browser\n",
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "\n",
    "#opening the homepage of amzon\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"twotabsearchtextbox\")   #locating search bar by id\n",
    "search_field_designation.send_keys(\"printers\")                                #searching for printers\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\")         #clicking the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Rating=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n",
      "Product urls of page 4 has been scraped.\n",
      "Product urls of page 5 has been scraped.\n",
      "Product urls of page 6 has been scraped.\n",
      "Product urls of page 7 has been scraped.\n",
      "Product urls of page 8 has been scraped.\n",
      "Product urls of page 9 has been scraped.\n",
      "Product urls of page 10 has been scraped.\n",
      "Product urls of page 11 has been scraped.\n",
      "Product urls of page 12 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=12\n",
    "urls =[]\n",
    "for page in range(start,end):       #for loop for scrapping 3 page\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls of products on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')           # Scraping the url from webelement\n",
    "            if url[0:4]=='http':                # Checking if the scraped data is a valid url or not\n",
    "                urls.append(url)                # Appending the url to urls list\n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        nxt_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')      # Locating the next_button which is active\n",
    "        if nxt_button.text == 'Next→':                                            # Checking if the button located is next button\n",
    "            nxt_button.click()                                                    # Clicking the next button\n",
    "            time.sleep(5)                                                         # time delay of 5 seconds\n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)                               # ReLoading the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pop = driver.find_element_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/i[2]')     # Button for expanding the specs\n",
    "        pop.click()\n",
    "        time.sleep(2)\n",
    "       \n",
    "        rev=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base a-text-center']/a\") #button for expanding review list\n",
    "        rev.click() \n",
    "        time.sleep(2)\n",
    "        \n",
    "        star5=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[1]\")  #locating the 5star ratings\n",
    "        star5.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)  #appending the review in Review list\n",
    "        \n",
    "        star4=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]\")  #locating the 4star rating\n",
    "        star4.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star3=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]\")  #locating the 3star rating\n",
    "        star3.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star2=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]\")  #locating the 2star rating\n",
    "        star2.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        time.sleep(2)\n",
    "        \n",
    "        star1=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]\")  #locating the 1star rating\n",
    "        star1.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Rating.append(\"NO rating\")   #appending the No rating if no rating is there   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 1094)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rating                                             Review\n",
      "0       5 star  superb, fantastic, excellent printer, value fo...\n",
      "1       5 star                                       Good Printer\n",
      "2       4 star                           You get what you pay for\n",
      "3       3 star              Do not purchase anything from Amazon.\n",
      "4       2 star                                 Worst product ever\n",
      "..         ...                                                ...\n",
      "788     5 star                       Epson - Never Disappoints Me\n",
      "789     4 star                         Nice and efficient printer\n",
      "790     3 star                           Zero maintenance printer\n",
      "791  NO rating                                          Two Stars\n",
      "792     5 star  No Support from on-line supplier Amazon and Ma...\n",
      "\n",
      "[793 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "amaz_print=pd.DataFrame({'Rating':Rating[:793],\n",
    "                'Review':Review[:793]})\n",
    "#printing dataframe\n",
    "print(amaz_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "amaz_print.to_csv('amaz_print.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating the chrome browser\n",
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "\n",
    "#opening the homepage of amzon\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"twotabsearchtextbox\")   #locating search bar by id\n",
    "search_field_designation.send_keys(\"monitors\")                                #searching for monitors\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\")         #clicking the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Rating=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n",
      "Product urls of page 4 has been scraped.\n",
      "Product urls of page 5 has been scraped.\n",
      "Product urls of page 6 has been scraped.\n",
      "Product urls of page 7 has been scraped.\n",
      "Product urls of page 8 has been scraped.\n",
      "Product urls of page 9 has been scraped.\n",
      "Product urls of page 10 has been scraped.\n",
      "Product urls of page 11 has been scraped.\n",
      "Product urls of page 12 has been scraped.\n",
      "Product urls of page 13 has been scraped.\n",
      "Product urls of page 14 has been scraped.\n",
      "Product urls of page 15 has been scraped.\n",
      "Product urls of page 16 has been scraped.\n",
      "Product urls of page 17 has been scraped.\n",
      "Product urls of page 18 has been scraped.\n",
      "Product urls of page 19 has been scraped.\n",
      "Product urls of page 20 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=20\n",
    "urls =[]\n",
    "for page in range(start,end):       #for loop for scrapping 3 page\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls of products on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')           # Scraping the url from webelement\n",
    "            if url[0:4]=='http':                # Checking if the scraped data is a valid url or not\n",
    "                urls.append(url)                # Appending the url to urls list\n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        nxt_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')      # Locating the next_button which is active\n",
    "        if nxt_button.text == 'Next→':                                            # Checking if the button located is next button\n",
    "            nxt_button.click()                                                    # Clicking the next button\n",
    "            time.sleep(5)                                                         # time delay of 5 seconds\n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)                               # ReLoading the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-feb620d8df66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mrating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#scrape rating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mRating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#appending the ratings in Ratings list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mreview\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#scraping reviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for url in urls[:]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pop = driver.find_element_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/i[2]')     # Button for expanding the specs\n",
    "        pop.click()\n",
    "        time.sleep(1)\n",
    "       \n",
    "        rev=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base a-text-center']/a\") #button for expanding review list\n",
    "        rev.click() \n",
    "        time.sleep(1)\n",
    "        \n",
    "        star5=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[1]\")  #locating the 5star ratings\n",
    "        star5.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)  #appending the review in Review list\n",
    "        \n",
    "        star4=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]\")  #locating the 4star rating\n",
    "        star4.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star3=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]\")  #locating the 3star rating\n",
    "        star3.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star2=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]\")  #locating the 2star rating\n",
    "        star2.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        star1=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]\")  #locating the 1star rating\n",
    "        star1.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Rating.append(\"NO rating\")   #appending the No rating if no rating is there   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4877, 5502)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Rating                                             Review\n",
      "0        5 star                            Awesome monitor overall\n",
      "1        5 star            Good Performance for a reasonable price\n",
      "2        4 star  Corners are turning to red if the monitor is o...\n",
      "3        3 star   Disappointment: Perfect specs but poor execution\n",
      "4        2 star                       Severe backlight bleed issue\n",
      "...         ...                                                ...\n",
      "4872     4 star   Few Dead Pixels on arrival else Fabulous Quality\n",
      "4873     3 star                                       Overall Good\n",
      "4874     2 star                     Bleeding, banding, acer never.\n",
      "4875  NO rating                            Awesome monitor overall\n",
      "4876     5 star            Good Performance for a reasonable price\n",
      "\n",
      "[4877 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "amaz_mon=pd.DataFrame({'Rating':Rating[:4877],\n",
    "                'Review':Review[:4877]})\n",
    "#printing dataframe\n",
    "print(amaz_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "amaz_mon.to_csv('amaz_print.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating the chrome browser\n",
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "\n",
    "#opening the homepage of amzon\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"twotabsearchtextbox\")   #locating search bar by id\n",
    "search_field_designation.send_keys(\"home theatre\")                                #searching for hometheatre\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\")         #clicking the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Rating=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n",
      "Product urls of page 4 has been scraped.\n",
      "Product urls of page 5 has been scraped.\n",
      "Product urls of page 6 has been scraped.\n",
      "Product urls of page 7 has been scraped.\n",
      "Product urls of page 8 has been scraped.\n",
      "Product urls of page 9 has been scraped.\n",
      "Product urls of page 10 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=10\n",
    "urls =[]\n",
    "for page in range(start,end):       #for loop for scrapping 10 page\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls of products on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')           # Scraping the url from webelement\n",
    "            if url[0:4]=='http':                # Checking if the scraped data is a valid url or not\n",
    "                urls.append(url)                # Appending the url to urls list\n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        nxt_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')      # Locating the next_button which is active\n",
    "        if nxt_button.text == 'Next→':                                            # Checking if the button located is next button\n",
    "            nxt_button.click()                                                    # Clicking the next button\n",
    "            time.sleep(5)                                                         # time delay of 5 seconds\n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)                               # ReLoading the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pop = driver.find_element_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/i[2]')     # Button for expanding the specs\n",
    "        pop.click()\n",
    "        time.sleep(1)\n",
    "       \n",
    "        rev=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base a-text-center']/a\") #button for expanding review list\n",
    "        rev.click() \n",
    "        time.sleep(1)\n",
    "        \n",
    "        star4=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]\")  #locating the 4star rating\n",
    "        star4.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star3=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]\")  #locating the 3star rating\n",
    "        star3.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star2=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]/td[2]\")  #locating the 2star rating\n",
    "        star2.click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        star1=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]/td[2]\")  #locating the 1star rating\n",
    "        star1.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Rating.append(\"NO rating\")   #appending the No rating if no rating is there   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(733, 1052)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rating                                             Review\n",
      "0    NO rating                                      Nice products\n",
      "1    NO rating                                      Nice products\n",
      "2    NO rating         Just okay. Not worth the value. Poor bass.\n",
      "3       4 star         Just okay. Not worth the value. Poor bass.\n",
      "4       4 star                                      Mesmerizing ✌\n",
      "..         ...                                                ...\n",
      "728     2 star              Not good at all just returning them .\n",
      "729     2 star      Superb Speakers & Bass Got In 1990 Rs Only :D\n",
      "730     4 star      Superb Speakers & Bass Got In 1990 Rs Only :D\n",
      "731     4 star  The subwoofer should be considered under testi...\n",
      "732     2 star  The subwoofer should be considered under testi...\n",
      "\n",
      "[733 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "amaz_hom=pd.DataFrame({'Rating':Rating[:733],\n",
    "                'Review':Review[:733]})\n",
    "#printing dataframe\n",
    "print(amaz_hom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "amaz_hom.to_csv('amaz_hom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activating the chrome browser\n",
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "\n",
    "#opening the homepage of amzon\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_id(\"twotabsearchtextbox\")   #locating search bar by id\n",
    "search_field_designation.send_keys(\"router\")                                #searching for hometheatre\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\")         #clicking the search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Rating=[]\n",
    "Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product urls of page 1 has been scraped.\n",
      "Product urls of page 2 has been scraped.\n",
      "Product urls of page 3 has been scraped.\n",
      "Product urls of page 4 has been scraped.\n",
      "Product urls of page 5 has been scraped.\n",
      "Product urls of page 6 has been scraped.\n",
      "Product urls of page 7 has been scraped.\n",
      "Product urls of page 8 has been scraped.\n",
      "Product urls of page 9 has been scraped.\n",
      "Product urls of page 10 has been scraped.\n",
      "Product urls of page 11 has been scraped.\n",
      "Product urls of page 12 has been scraped.\n",
      "Product urls of page 13 has been scraped.\n",
      "Product urls of page 14 has been scraped.\n",
      "Product urls of page 15 has been scraped.\n",
      "Product urls of page 16 has been scraped.\n",
      "Product urls of page 17 has been scraped.\n",
      "Product urls of page 18 has been scraped.\n",
      "Product urls of page 19 has been scraped.\n"
     ]
    }
   ],
   "source": [
    "#scrapping the required details\n",
    "start=0\n",
    "end=19\n",
    "urls =[]\n",
    "for page in range(start,end):       #for loop for scrapping 10 page\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        \n",
    "        # appending all the urls of products on current page to urls list\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')           # Scraping the url from webelement\n",
    "            if url[0:4]=='http':                # Checking if the scraped data is a valid url or not\n",
    "                urls.append(url)                # Appending the url to urls list\n",
    "        print(\"Product urls of page {} has been scraped.\".format(page+1))\n",
    "        \n",
    "        # Moving to next page\n",
    "        nxt_button = driver.find_element_by_xpath('//li[@class=\"a-last\"]/a')      # Locating the next_button which is active\n",
    "        if nxt_button.text == 'Next→':                                            # Checking if the button located is next button\n",
    "            nxt_button.click()                                                    # Clicking the next button\n",
    "            time.sleep(5)                                                         # time delay of 5 seconds\n",
    "        # If the current active button is not next button, the we will check if the next button is inactive or not    \n",
    "        elif driver.find_element_by_xpath('//li[@class=\"a-disabled a-last\"]/a').text == 'Next→':    \n",
    "            print(\"No new pages exist. Breaking the loop\")  # Printing message and breakinf loop if we have reached the last page\n",
    "            break\n",
    "            \n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")\n",
    "        next_page = nxt_button.get_attribute('href')        # Extracting the url of next page\n",
    "        driver.get(next_page)                               # ReLoading the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:]:\n",
    "    driver.get(url)                                                        # Loading the webpage by url\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        pop = driver.find_element_by_xpath('//a[@class=\"a-popover-trigger a-declarative\"]/i[2]')     # Button for expanding the specs\n",
    "        pop.click()\n",
    "        time.sleep(1)\n",
    "       \n",
    "        rev=driver.find_element_by_xpath(\"//div[@class='a-section a-spacing-base a-text-center']/a\") #button for expanding review list\n",
    "        rev.click() \n",
    "        time.sleep(1)\n",
    "        \n",
    "        star3=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]\")  #locating the 3star rating\n",
    "        star3.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "        star2=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]/td[2]\")  #locating the 2star rating\n",
    "        star2.click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        time.sleep(1)\n",
    "        \n",
    "        star1=driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]/td[2]\")  #locating the 1star rating\n",
    "        star1.click() \n",
    "        \n",
    "        rating=driver.find_element_by_xpath(\"//div[@class='a-row a-spacing-micro a-size-base']/span[1]\") #scrape rating\n",
    "        Rating.append(rating.text)  #appending the ratings in Ratings list\n",
    "        \n",
    "        review=driver.find_element_by_xpath(\"//a[@class='a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold']/span\") #scraping reviews\n",
    "        Review.append(review.text)   #appending the review in Review list\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Rating.append(\"NO rating\")   #appending the No rating if no rating is there   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 735)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rating                                             Review\n",
      "0    NO rating  Super feature-filled hardware from the leader ...\n",
      "1       4 star  Super feature-filled hardware from the leader ...\n",
      "2       4 star                                    Average Router!\n",
      "3    NO rating                  Poor 2.4Ghz performance and range\n",
      "4    NO rating                  Poor 2.4Ghz performance and range\n",
      "..         ...                                                ...\n",
      "455     2 star                not really a traffic sensing router\n",
      "456     2 star                not really a traffic sensing router\n",
      "457     3 star  So simple to Configure yet difficult to fathom...\n",
      "458     2 star                  Hangs periodically for no reason.\n",
      "459     2 star                  Hangs periodically for no reason.\n",
      "\n",
      "[460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "amaz_rout=pd.DataFrame({'Rating':Rating[:460],\n",
    "                'Review':Review[:460]})\n",
    "#printing dataframe\n",
    "print(amaz_rout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "amaz_rout.to_csv('amaz_rout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "urls=[]\n",
    "Review=[]\n",
    "Rating=[]\n",
    "\n",
    "#Taking 10 pages into consideration using for loop\n",
    "for i in range(50):\n",
    "    url=driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a\").get_attribute('href')\n",
    "    driver.get(url)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review.append(k.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rating              Review\n",
      "0        5           Brilliant\n",
      "1        5      Simply awesome\n",
      "2        5    Perfect product!\n",
      "3        5           Fabulous!\n",
      "4        5   Worth every penny\n",
      "..     ...                 ...\n",
      "495      5       Great product\n",
      "496      5   Worth every penny\n",
      "497      4         Good choice\n",
      "498      5  Highly recommended\n",
      "499      5    Perfect product!\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "flip_phon=pd.DataFrame({'Rating':Rating[:500],\n",
    "                'Review':Review[:500]})\n",
    "#printing dataframe\n",
    "print(flip_phon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "flip_phon.to_csv('flip_phon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "driver.get('https://www.flipkart.com/mi-notebook-14-core-i5-10th-gen-8-gb-256-gb-ssd-windows-10-home-jyu4298in-thin-light-laptop/product-reviews/itm447bff0c4ffc5?pid=COMFZAM2ZJB38YSS&lid=LSTCOMFZAM2ZJB38YSSJBNZPH&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "urls=[]\n",
    "Review=[]\n",
    "Rating=[]\n",
    "\n",
    "#Taking 10 pages into consideration using for loop\n",
    "for i in range(50):\n",
    "    url=driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a\").get_attribute('href')\n",
    "    driver.get(url)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review.append(k.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rating             Review\n",
      "0        5             Super!\n",
      "1        5  Terrific purchase\n",
      "2        5  Worth every penny\n",
      "3        5          Fabulous!\n",
      "4        5            Awesome\n",
      "..     ...                ...\n",
      "495      5             Super!\n",
      "496      5     Classy product\n",
      "497      4        Pretty good\n",
      "498      4    Worth the money\n",
      "499      4          Very Good\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "flip_phon2=pd.DataFrame({'Rating':Rating[:500],\n",
    "                'Review':Review[:500]})\n",
    "#printing dataframe\n",
    "print(flip_phon2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "flip_phon2.to_csv('flip_phon2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "driver.get('https://www.flipkart.com/hp-pavilion-gaming-ryzen-5-quad-core-3550h-8-gb-1-tb-hdd-windows-10-home-4-gb-graphics-nvidia-geforce-gtx-1650-15-ec0101ax-laptop/product-reviews/itma1af6bf593dc8?pid=COMFSFNVDXG74QXR&lid=LSTCOMFSFNVDXG74QXRY8FRH2&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "urls=[]\n",
    "Review=[]\n",
    "Rating=[]\n",
    "\n",
    "#Taking 10 pages into consideration using for loop\n",
    "for i in range(174):\n",
    "    url=driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a\").get_attribute('href')\n",
    "    driver.get(url)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review.append(k.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1740, 1740)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rating           Review\n",
      "0         5        Must buy!\n",
      "1         5   Simply awesome\n",
      "2         5        Must buy!\n",
      "3         5         Terrific\n",
      "4         4  Value-for-money\n",
      "...     ...              ...\n",
      "1735      4     Nice product\n",
      "1736      5   Classy product\n",
      "1737      4        Very Good\n",
      "1738      4      Good choice\n",
      "1739      4  Value-for-money\n",
      "\n",
      "[1740 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "flip_lap=pd.DataFrame({'Rating':Rating[:1740],\n",
    "                'Review':Review[:1740]})\n",
    "#printing dataframe\n",
    "print(flip_lap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "flip_lap.to_csv('flip_lap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "driver.get('https://www.flipkart.com/realme-c21-cross-black-64-gb/product-reviews/itmf4062d3f37c1a?pid=MOBGF489G9HRWFZ9&lid=LSTMOBGF489G9HRWFZ9BYFZCR&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "urls=[]\n",
    "Review=[]\n",
    "Rating=[]\n",
    "\n",
    "#Taking 10 pages into consideration using for loop\n",
    "for i in range(183):\n",
    "    url=driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a\").get_attribute('href')\n",
    "    driver.get(url)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1830, 1830)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rating             Review\n",
      "0         5          Brilliant\n",
      "1         5          Brilliant\n",
      "2         3               Good\n",
      "3         3               Nice\n",
      "4         4        Pretty good\n",
      "...     ...                ...\n",
      "1825      4          Wonderful\n",
      "1826      4          Wonderful\n",
      "1827      5  Terrific purchase\n",
      "1828      5     Classy product\n",
      "1829      3               Nice\n",
      "\n",
      "[1830 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "flip_phon3=pd.DataFrame({'Rating':Rating[:1830],\n",
    "                'Review':Review[:1830]})\n",
    "#printing dataframe\n",
    "print(flip_phon3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "flip_phon3.to_csv('flip_phon3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"C:\\Web driver\\chromedriver\")\n",
    "driver.get('https://www.flipkart.com/redmi-9i-midnight-black-64-gb/product-reviews/itm0e1018dac2627?pid=MOBFV8RYKWQ3HACE&lid=LSTMOBFV8RYKWQ3HACEV2QOWQ&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "urls=[]\n",
    "Review=[]\n",
    "Rating=[]\n",
    "\n",
    "#Taking 500 pages into consideration using for loop\n",
    "for i in range(500):\n",
    "    url=driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a\").get_attribute('href')\n",
    "    driver.get(url)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Review),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rating                Review\n",
      "0         5             Just wow!\n",
      "1         4       Worth the money\n",
      "2         5      Perfect product!\n",
      "3         5             Brilliant\n",
      "4         3                  Nice\n",
      "...     ...                   ...\n",
      "1735      5             Excellent\n",
      "1736      5             Must buy!\n",
      "1737      5              Terrific\n",
      "1738      4  Good quality product\n",
      "1739      5             Wonderful\n",
      "\n",
      "[1740 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "flip_phon4=pd.DataFrame({'Rating':Rating[:1740],\n",
    "                'Review':Review[:1740]})\n",
    "#printing dataframe\n",
    "print(flip_phon4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv\n",
    "flip_phon4.to_csv('flip_phon4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
